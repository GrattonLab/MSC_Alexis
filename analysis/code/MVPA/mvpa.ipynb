{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/mvpa2/base/hdf5.py:40: H5pyDeprecationWarning: The h5py.highlevel module is deprecated, code should import directly from h5py, e.g. 'from h5py import File'.\n",
      "  import h5py.highlevel  # >= 2.8.0, https://github.com/h5py/h5py/issues/1063\n",
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/pydicom/__init__.py:55: DeprecationWarning: Python 2 will no longer be supported after the pydicom v1.4 release\n",
      "  warnings.warn(msg, DeprecationWarning)\n",
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/mvpa2/testing/tools.py:81: DeprecationWarning: Importing from numpy.testing.decorators is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing.decorators import skipif\n"
     ]
    }
   ],
   "source": [
    "#import mvpa2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import sklearn\n",
    "#to manipulate data\n",
    "from mvpa2.datasets import *\n",
    "import scipy.io\n",
    "\n",
    "from mvpa2.suite import *\n",
    "if __debug__:\n",
    "    debug.active.append('SMLR_')\n",
    "    \n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a dict for task\n",
    "matFile = scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/mem/MSC02_parcel_corrmat.mat')\n",
    "#convert to numpy array\n",
    "task_FC=np.array(matFile['parcel_corrmat'])\n",
    "#Index of upper triangle of matrix \n",
    "nrois=333\n",
    "nsess=10\n",
    "task_mask=np.triu_indices(nrois, 1)\n",
    "task_corrlin=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "count=0\n",
    "#loop through all 10 days to reshape correlations into linear form\n",
    "for sess in range(nsess):\n",
    "    tmp=task_FC[:,:,sess]\n",
    "    task_corrlin[count]=tmp[task_mask]\n",
    "    count=count+1\n",
    "\n",
    "#makes a dict for rest\n",
    "matFile = scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/rest/MSC02_parcel_corrmat.mat')\n",
    "#convert to numpy array\n",
    "rest_FC=np.array(matFile['parcel_corrmat'])\n",
    "#Index of upper triangle of matrix \n",
    "nrois=333\n",
    "nsess=10\n",
    "rest_mask=np.triu_indices(nrois, 1)\n",
    "rest_corrlin=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "count=0\n",
    "#loop through all 10 days to reshape correlations into linear form\n",
    "for sess in range(nsess):\n",
    "    tmp=rest_FC[:,:,sess]\n",
    "    rest_corrlin[count]=tmp[rest_mask]\n",
    "    count=count+1\n",
    "    \n",
    "#makes a dict for test task\n",
    "matFile = scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/motor/MSC02_parcel_corrmat.mat')\n",
    "#convert to numpy array\n",
    "motor_FC=np.array(matFile['parcel_corrmat'])\n",
    "#Index of upper triangle of matrix \n",
    "nrois=333\n",
    "nsess=10\n",
    "test_mask=np.triu_indices(nrois, 1)\n",
    "motor_corrlin=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "count=0\n",
    "#loop through all 10 days to reshape correlations into linear form\n",
    "for sess in range(nsess):\n",
    "    tmp=motor_FC[:,:,sess]\n",
    "    motor_corrlin[count]=tmp[test_mask]\n",
    "    count=count+1\n",
    "#corrlin.shape\n",
    "#task_ds=Dataset(corrlin)\n",
    "#ds.shape\n",
    "#ds.nfeatures\n",
    "#ds.nsamples\n",
    "#create a training dataset from the labeled features, targets 1:0 task:rest chunks=number of days\n",
    "task_ds=dataset_wizard(samples=task_corrlin, targets=1, chunks=range(1,11))\n",
    "rest_ds=dataset_wizard(samples=rest_corrlin, targets=0, chunks=range(1,11))\n",
    "trainpat=vstack((task_ds, rest_ds))\n",
    "\n",
    "#create pattern for testing dataset\n",
    "test_ds=dataset_wizard(samples=motor_corrlin, targets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating SMLR classifier\n",
      "[SMLR_] DBG:                     hstacking 1s for bias\n",
      "[SMLR_] DBG:                     Calling stepwise_regression. Seed 275587169\n"
     ]
    }
   ],
   "source": [
    "#setup SMLR classifier\n",
    "print \"evaluating SMLR classifier\"\n",
    "smlr=SMLR(fit_all_weights=True)\n",
    "#enable saving of estimates used for prediction\n",
    "smlr.ca.enable('estimates')\n",
    "#train with the known points\n",
    "smlr.train(trainpat)\n",
    "#run predictions on test values\n",
    "pre=smlr.predict(test_ds.samples)\n",
    "#caluclate confusion matrix\n",
    "smlr_confusion=ConfusionMatrix(labels=trainpat.UT, targets=test_ds.targets, predictions=pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating linear SVM classifier\n"
     ]
    }
   ],
   "source": [
    "#linear SVM\n",
    "print \"evaluating linear SVM classifier\"\n",
    "lsvm=LinearNuSVMC(probability=1)\n",
    "#save estimates\n",
    "lsvm.ca.enable('estimates')\n",
    "#train with known points\n",
    "lsvm.train(trainpat)\n",
    "#run predictions on test values\n",
    "pre=lsvm.predict(test_ds.samples)\n",
    "#calculate confusion matrix\n",
    "lsvm_confusion=ConfusionMatrix(labels=trainpat.UT, targets=test_ds.targets,predictions=pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating linear SVM classifier with SMLR features\n"
     ]
    }
   ],
   "source": [
    "#train SVM with selected features\n",
    "print \"evaluating linear SVM classifier with SMLR features\"\n",
    "keepInd=(np.abs(smlr.weights).mean(axis=1)!=0)\n",
    "newtrainpat=trainpat[:, keepInd]\n",
    "newtestpat=test_ds[:, keepInd]\n",
    "#train with known points\n",
    "lsvm.train(newtrainpat)\n",
    "#run prediction on test values\n",
    "pre=lsvm.predict(newtestpat.samples)\n",
    "#calculate confusion matrix\n",
    "lsvm_confusion_sparse=ConfusionMatrix(labels=newtrainpat.UT, targets=newtestpat.targets, predictions=pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMLR Percent Correct:\t60% (Retained 36/110556 features)\n",
      "linear-SVM Percent Correct:\t30%\n",
      "linear-SVM Percent Correct (with 18 features from SMLR):\t60%\n"
     ]
    }
   ],
   "source": [
    "print \"SMLR Percent Correct:\\t%g%% (Retained %d/%d features)\" % \\\n",
    "    (smlr_confusion.percent_correct,\n",
    "     (smlr.weights!=0).sum(), np.prod(smlr.weights.shape))\n",
    "print \"linear-SVM Percent Correct:\\t%g%%\" % \\\n",
    "    (lsvm_confusion.percent_correct)\n",
    "print \"linear-SVM Percent Correct (with %d features from SMLR):\\t%g%%\" % \\\n",
    "    (keepInd.sum(), lsvm_confusion_sparse.percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4],\n",
       "       [0, 6]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smlr_confusion.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset: 20x55278@float64, <sa: targets> stats: mean=0.0280829 std=0.229266 var=0.052563 min=-1.05039 max=2.03915\\nSequence statistics for 20 entries from set [0, 1]\\nCounter-balance table for orders up to 2:\\nTargets/Order O1    |  O2    |\\n      0:       9 0  |   8 0  |\\n      1:       1 9  |   2 8  |\\nCorrelations: min=-1 max=0.8 mean=-0.053 sum(abs)=9'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainpat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create objects holding linear svm, cross validation scheme==leave one out cross validation, accuracy\n",
    "cv = CrossValidation(LinearCSVMC(), NFoldPartitioner(), \n",
    "                     enable_ca=['stats'], \n",
    "                     errorfx=lambda p, t: np.mean(p == t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = cv(trainpat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset: 10x1@float64, <sa: cvfolds> stats: mean=0.95 std=0.15 var=0.0225 min=0.5 max=1\\n'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44999999999999996"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res.samples) - (1.0 / len(trainpat.UT)) # % above chance accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CrossValidation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'function' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-48dfe902fc37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m     \u001b[0mExamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3118\u001b[0;31m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3119\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'function' and 'int'"
     ]
    }
   ],
   "source": [
    "np.mean(res.samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(array([[1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [0.5]]), sa=SampleAttributesCollection(items=[ArrayCollectable(name='cvfolds', doc=None, value=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), length=10)]), fa=FeatureAttributesCollection(items=[]), a=DatasetAttributesCollection(items=[]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  1],\n",
       "       [ 0,  9]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.ca.stats.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 55278)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainpat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Dataset.summary of Dataset(array([[ 0.00095655, -0.07663061,  0.23755615, ...,  0.51705891,\n",
       "         0.1983052 ,  0.03582447],\n",
       "       [-0.20647831, -0.04299903,  0.43117783, ...,  0.31590771,\n",
       "         0.26129547,  0.2377527 ],\n",
       "       [-0.01635137, -0.11918725,  0.31998732, ...,  0.61881407,\n",
       "         0.51909949,  0.27669716],\n",
       "       ...,\n",
       "       [-0.16529865, -0.08329263,  0.37580496, ...,  0.36276519,\n",
       "         0.3779244 ,  0.29793391],\n",
       "       [-0.07441239, -0.07626242,  0.31809336, ...,  0.36081897,\n",
       "         0.47208516,  0.29183056],\n",
       "       [-0.3631561 , -0.0513033 ,  0.16918412, ...,  0.36356048,\n",
       "         0.51770127,  0.26640822]]), sa=SampleAttributesCollection(items=[ArrayCollectable(name='chunks', doc=None, value=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  1,  2,  3,  4,  5,  6,  7,\n",
       "        8,  9, 10]), length=20), ArrayCollectable(name='targets', doc=None, value=array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), length=20)]), fa=FeatureAttributesCollection(items=[]), a=DatasetAttributesCollection(items=[]))>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainpat.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import mvpa2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import sklearn\n",
    "#to manipulate data\n",
    "from mvpa2.datasets import *\n",
    "import scipy.io\n",
    "from mvpa2.suite import *\n",
    "if __debug__:\n",
    "    debug.active.append('SMLR_')\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a dict for task\n",
    "matFile = scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/mem/MSC02_parcel_corrmat.mat')\n",
    "#convert to numpy array\n",
    "task_FC=np.array(matFile['parcel_corrmat'])\n",
    "#Index of upper triangle of matrix \n",
    "nrois=333\n",
    "nsess=10\n",
    "task_mask=np.triu_indices(nrois, 1)\n",
    "task_corrlin=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "count=0\n",
    "#loop through all 10 days to reshape correlations into linear form\n",
    "for sess in range(nsess):\n",
    "    tmp=task_FC[:,:,sess]\n",
    "    task_corrlin[count]=tmp[task_mask]\n",
    "    count=count+1\n",
    "\n",
    "#makes a dict for rest\n",
    "matFile = scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/rest/MSC02_parcel_corrmat.mat')\n",
    "#convert to numpy array\n",
    "rest_FC=np.array(matFile['parcel_corrmat'])\n",
    "#Index of upper triangle of matrix \n",
    "nrois=333\n",
    "nsess=10\n",
    "rest_mask=np.triu_indices(nrois, 1)\n",
    "rest_corrlin=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "count=0\n",
    "#loop through all 10 days to reshape correlations into linear form\n",
    "for sess in range(nsess):\n",
    "    tmp=rest_FC[:,:,sess]\n",
    "    rest_corrlin[count]=tmp[rest_mask]\n",
    "    count=count+1\n",
    "    \n",
    "#makes a dict for test task\n",
    "matFile = scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/mem/MSC03_parcel_corrmat.mat')\n",
    "#convert to numpy array\n",
    "motor_FC=np.array(matFile['parcel_corrmat'])\n",
    "motor_FC=np.nan_to_num(motor_FC)\n",
    "#Index of upper triangle of matrix \n",
    "nrois=333\n",
    "nsess=10\n",
    "test_mask=np.triu_indices(nrois, 1)\n",
    "motor_corrlin=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "count=0\n",
    "#loop through all 10 days to reshape correlations into linear form\n",
    "for sess in range(nsess):\n",
    "    tmp=motor_FC[:,:,sess]\n",
    "    motor_corrlin[count]=tmp[test_mask]\n",
    "    count=count+1\n",
    "\n",
    "#makes a dict for test task\n",
    "matFile = scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/rest/MSC03_parcel_corrmat.mat')\n",
    "#convert to numpy array\n",
    "r_FC=np.array(matFile['parcel_corrmat'])\n",
    "r_FC=np.nan_to_num(r_FC)\n",
    "#Index of upper triangle of matrix \n",
    "nrois=333\n",
    "nsess=10\n",
    "r_mask=np.triu_indices(nrois, 1)\n",
    "r_corrlin=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "count=0\n",
    "#loop through all 10 days to reshape correlations into linear form\n",
    "for sess in range(nsess):\n",
    "    tmp=r_FC[:,:,sess]\n",
    "    r_corrlin[count]=tmp[test_mask]\n",
    "    count=count+1\n",
    "\n",
    "#corrlin.shape\n",
    "#task_ds=Dataset(corrlin)\n",
    "#ds.shape\n",
    "#ds.nfeatures\n",
    "#ds.nsamples\n",
    "#create a training dataset from the labeled features, targets 1:0 task:rest chunks=number of days\n",
    "task_ds=dataset_wizard(samples=task_corrlin, targets=1, chunks=range(10))\n",
    "rest_ds=dataset_wizard(samples=rest_corrlin, targets=0, chunks=range(10))\n",
    "trainpat=vstack((task_ds, rest_ds))\n",
    "\n",
    "#create pattern for testing dataset\n",
    "test_ds=dataset_wizard(samples=motor_corrlin, targets=1, chunks=range(10))\n",
    "r_df=dataset_wizard(samples=r_corrlin, targets=0, chunks=range(10))\n",
    "testpat=vstack((test_ds, r_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating linear SVM classifier\n",
      "linear-SVM Percent Correct:\t30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/mvpa2/misc/attrmap.py:153: FutureWarning: Conversion of the second argument of issubdtype from `str` to `str` is deprecated. In future, it will be treated as `np.string_ == np.dtype(str).type`.\n",
      "  if not np.issubdtype(attr.dtype, str) and not self.mapnumeric:\n",
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/mvpa2/clfs/libsvmc/svm.py:215: FutureWarning: Conversion of the second argument of issubdtype from `'c'` to `str` is deprecated. In future, it will be treated as `np.string_ == np.dtype('c').type`.\n",
      "  if ( np.issubdtype(self.ca.trained_targets.dtype, 'c') or\n",
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/mvpa2/clfs/libsvmc/svm.py:216: FutureWarning: Conversion of the second argument of issubdtype from `'U'` to `unicode` is deprecated. In future, it will be treated as `np.unicode_ == np.dtype('U').type`.\n",
      "  np.issubdtype(self.ca.trained_targets.dtype, 'U') ):\n",
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/mvpa2/clfs/transerror.py:681: RuntimeWarning: invalid value encountered in divide\n",
      "  stats['TPR'] = stats['TP'] / (1.0*stats['P'])\n",
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/mvpa2/clfs/transerror.py:688: RuntimeWarning: invalid value encountered in divide\n",
      "  stats['SPC'] = (stats['TN']) / (1.0*stats['FP'] + stats['TN'])\n"
     ]
    }
   ],
   "source": [
    "#linear SVM\n",
    "print \"evaluating linear nu SVM classifier\"\n",
    "lsvm=LinearNuSVMC()\n",
    "#save estimates\n",
    "lsvm.ca.enable('estimates')\n",
    "#train with known points\n",
    "lsvm.train(trainpat)\n",
    "#run predictions on test values\n",
    "pre=lsvm.predict(test_ds.samples)\n",
    "#calculate confusion matrix\n",
    "lsvm_confusion=ConfusionMatrix(labels=trainpat.UT, targets=test_ds.targets,predictions=pre)\n",
    "print \"linear-SVM nu Percent Correct:\\t%g%%\" % \\\n",
    "    (lsvm_confusion.percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating SVM classifier\n",
      "linear-SVM Percent Correct:\t20%\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "print \"evaluating standard SVM classifier\"\n",
    "svm=SVM()\n",
    "#save estimates\n",
    "svm.ca.enable('estimates')\n",
    "#train with known points\n",
    "svm.train(trainpat)\n",
    "#run predictions on test values\n",
    "pre=svm.predict(test_ds.samples)\n",
    "#calculate confusion matrix\n",
    "svm_confusion=ConfusionMatrix(labels=trainpat.UT, targets=test_ds.targets,predictions=pre)\n",
    "print \"Standard SVM Percent Correct:\\t%g%%\" % \\\n",
    "    (svm_confusion.percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating linear SVM classifier\n",
      "linear-SVM Percent Correct:\t20%\n"
     ]
    }
   ],
   "source": [
    "#Linear SVM\n",
    "print \"evaluating linear SVM classifier\"\n",
    "lcsvmc=LinearCSVMC()\n",
    "#save estimates\n",
    "lcsvmc.ca.enable('estimates')\n",
    "#train with known points\n",
    "lcsvmc.train(trainpat)\n",
    "#run predictions on test values\n",
    "pre=lcsvmc.predict(test_ds.samples)\n",
    "#calculate confusion matrix\n",
    "lcsvmc_confusion=ConfusionMatrix(labels=trainpat.UT, targets=test_ds.targets,predictions=pre)\n",
    "print \"linear-SVM Percent Correct:\\t%g%%\" % \\\n",
    "    (lcsvmc_confusion.percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating C SVM classifier using radial basis function kernel\n",
      "WARNING: TODO: Computation of default C is not yet implemented for non-linear SVMs. Assigning 1.0\n",
      " * Please note: warnings are printed only once, but underlying problem might occur many times *\n",
      "linear-SVM Percent Correct:\t0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/mvpa2/clfs/transerror.py:685: RuntimeWarning: invalid value encountered in divide\n",
      "  stats['PPV'] = stats['TP'] / (1.0*stats[\"P'\"])\n",
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/mvpa2/clfs/transerror.py:686: RuntimeWarning: invalid value encountered in divide\n",
      "  stats['NPV'] = stats['TN'] / (1.0*stats[\"N'\"])\n",
      "//anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/mvpa2/clfs/transerror.py:687: RuntimeWarning: invalid value encountered in divide\n",
      "  stats['FDR'] = stats['FP'] / (1.0*stats[\"P'\"])\n"
     ]
    }
   ],
   "source": [
    "#Linear SVM\n",
    "print \"evaluating C SVM classifier using radial basis function kernel\"\n",
    "RBfcsvmc=RbfCSVMC()\n",
    "#save estimates\n",
    "RBfcsvmc.ca.enable('estimates')\n",
    "#train with known points\n",
    "RBfcsvmc.train(trainpat)\n",
    "#run predictions on test values\n",
    "pre=RBfcsvmc.predict(test_ds.samples)\n",
    "#calculate confusion matrix\n",
    "RBfcsvmc_confusion=ConfusionMatrix(labels=trainpat.UT, targets=test_ds.targets,predictions=pre)\n",
    "print \"linear-SVM Percent Correct:\\t%g%%\" % \\\n",
    "    (RBfcsvmc_confusion.percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create objects holding linear svm, cross validation scheme==leave one out cross validation, accuracy\n",
    "cv = CrossValidation(LinearCSVMC(), NFoldPartitioner(), #Nfold is leave one out; selects one chunk at a time chunk being day\n",
    "                     enable_ca=['stats'], \n",
    "                     errorfx=lambda p, t: np.mean(p == t))#reports accuracy instead of error\n",
    "#classifier predictions and the target values stored in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res = cv(trainpat)\n",
    "#print \"accuracy of linear svmc\"\n",
    "#np.mean(res.samples) - (1.0 / len(trainpat.UT)) # % above chance accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre=cv.train(trainpat)\n",
    "#call the classifier directly to test the new dataset\n",
    "#this computes the error so lower values represent more accurate classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=cv(testpat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre #prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [1. ],\n",
       "       [0.5]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.samples #results of all cross validated folds. \n",
    "#Accuracy and a sample per fold \n",
    "#looks like it was able to classify across 9 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------.\n",
      "predictions\\targets   0    1\n",
      "            `------  ---  --- P' N' FP FN PPV NPV TPR SPC FDR MCC F1 AUC\n",
      "         0           10    0  10 10  0  0  1   1   1   1   0   1   1  1\n",
      "         1            0   10  10 10  0  0  1   1   1   1   0   1   1  1\n",
      "Per target:          ---  ---\n",
      "         P           10   10\n",
      "         N           10   10\n",
      "         TP          10   10\n",
      "         TN          10   10\n",
      "Summary \\ Means:     ---  --- 10 10  0  0  1   1   1   1   0   1   1  1\n",
      "       CHI^2         20  p=0.00017\n",
      "        ACC           1\n",
      "        ACC%         100\n",
      "     # of sets       10   ACC(i) = 1+0*i p=1 r=0 r^2=0\n",
      "\n",
      "Statistics computed in 1-vs-rest fashion per each target.\n",
      "Abbreviations (for details see http://en.wikipedia.org/wiki/ROC_curve):\n",
      " TP : true positive (AKA hit)\n",
      " TN : true negative (AKA correct rejection)\n",
      " FP : false positive (AKA false alarm, Type I error)\n",
      " FN : false negative (AKA miss, Type II error)\n",
      " TPR: true positive rate (AKA hit rate, recall, sensitivity)\n",
      "      TPR = TP / P = TP / (TP + FN)\n",
      " FPR: false positive rate (AKA false alarm rate, fall-out)\n",
      "      FPR = FP / N = FP / (FP + TN)\n",
      " ACC: accuracy\n",
      "      ACC = (TP + TN) / (P + N)\n",
      " SPC: specificity\n",
      "      SPC = TN / (FP + TN) = 1 - FPR\n",
      " PPV: positive predictive value (AKA precision)\n",
      "      PPV = TP / (TP + FP)\n",
      " NPV: negative predictive value\n",
      "      NPV = TN / (TN + FN)\n",
      " FDR: false discovery rate\n",
      "      FDR = FP / (FP + TP)\n",
      " MCC: Matthews Correlation Coefficient\n",
      "      MCC = (TP*TN - FP*FN)/sqrt(P N P' N')\n",
      " F1 : F1 score\n",
      "      F1 = 2TP / (P + P') = 2TP / (2TP + FP + FN)\n",
      " AUC: Area under (AUC) curve\n",
      " CHI^2: Chi-square of confusion matrix\n",
      " LOE(ACC): Linear Order Effect in ACC across sets\n",
      " # of sets: number of target/prediction sets which were provided\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print cv.ca.stats.as_string(description=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0]\n",
      " [ 0 10]]\n"
     ]
    }
   ],
   "source": [
    "print cv.ca.stats.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

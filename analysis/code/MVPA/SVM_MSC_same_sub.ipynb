{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_var_same_sub(subid='sub', trainList=['mem','mixed','motor'], predictList=['mem','mixed','motor']):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from mvpa2.datasets import dataset_wizard, vstack\n",
    "    from mvpa2.generators.partition import NFoldPartitioner\n",
    "    from mvpa2.measures.base import CrossValidation\n",
    "    from mvpa2.clfs.meta import MappedClassifier\n",
    "    from mvpa2.clfs.svm import LinearCSVMC\n",
    "    #import mvpa2\n",
    "    #import mvpa2.datasets\n",
    "    import scipy.io\n",
    "    #from mvpa2.suite import *\n",
    "    #Consistent parameters to use for editing datasets\n",
    "    nrois=333\n",
    "    nsess=10\n",
    "    nsub=10\n",
    "    #make an empty df to store accuracy scores from each run\n",
    "    accTable=[]\n",
    "    for i in trainList:\n",
    "        #Load task FC\n",
    "        taskFile=scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/'+i+'/'+subid+'_parcel_corrmat.mat')\n",
    "        #Convert to numpy array\n",
    "        task_FC=np.array(taskFile['parcel_corrmat'])\n",
    "        #Replace nans and infs with zero\n",
    "        task_FC=np.nan_to_num(task_FC)\n",
    "        #Index upper triangle of matrix\n",
    "        task_mask=np.triu_indices(nrois,1)\n",
    "        task_ds=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "        task_value=0\n",
    "        #Loop through all 10 days to reshape correlations into linear form\n",
    "        for sess in range(nsess):\n",
    "            tmp=task_FC[:,:,sess]\n",
    "            task_ds[task_value]=tmp[task_mask]\n",
    "            task_value=task_value+1\n",
    "        #Load rest\n",
    "        restFile=scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/rest/'+subid+'_parcel_corrmat.mat')\n",
    "        rest_FC=np.array(restFile['parcel_corrmat'])\n",
    "        rest_FC=np.nan_to_num(rest_FC)\n",
    "        rest_mask=np.triu_indices(nrois,1)\n",
    "        rest_ds=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "        rest_value=0\n",
    "        for sess in range(nsess):\n",
    "            tmp=rest_FC[:,:,sess]\n",
    "            rest_ds[rest_value]=tmp[rest_mask]\n",
    "            rest_value=rest_value+1\n",
    "        #Create a training dataset targets 1/0 ==task/rest, chunk=#days\n",
    "        taskdf=dataset_wizard(samples=task_ds, targets=1, chunks=range(10))\n",
    "        restdf=dataset_wizard(samples=rest_ds, targets=0, chunks=range(10))\n",
    "        training=vstack((taskdf, restdf))\n",
    "        #Linear SVM with cross validation scheme leave one out, output is the accuracy\n",
    "        cv=CrossValidation(LinearCSVMC(), NFoldPartitioner(), \n",
    "                      enable_ca=['stats'],\n",
    "                      errorfx=lambda p, t: np.mean(p == t))\n",
    "        #Train the classifier         \n",
    "        cv.train(training)\n",
    "        acc_scores_per_task=[]\n",
    "        #Lets loop through all scenerios for sub and train of interest\n",
    "        for j in predictList:\n",
    "            #Load testing set\n",
    "            testFile=scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/'+j+'/'+subid+'_parcel_corrmat.mat')\n",
    "            test_FC=np.array(testFile['parcel_corrmat'])\n",
    "            test_FC=np.nan_to_num(test_FC)\n",
    "            test_mask=np.triu_indices(nrois,1)\n",
    "            test_ds=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "            test_value=0\n",
    "            for sess in range(nsess):\n",
    "                tmp=test_FC[:,:,sess]\n",
    "                test_ds[test_value]=tmp[task_mask]\n",
    "                test_value=test_value+1\n",
    "            #Create testing dataset\n",
    "            testing=dataset_wizard(samples=test_ds, targets=1, chunks=range(10))\n",
    "            #Time to train\n",
    "            pre=cv(testing)\n",
    "            #prediction accuracy\n",
    "            acc=np.mean(pre)\n",
    "            acc_scores_per_task.append(acc)\n",
    "        tmp_df=pd.DataFrame({'Test_variables':predictList, i:acc_scores_per_task}).set_index('Test_variables')\n",
    "        accTable.append(tmp_df)\n",
    "    accTable=pd.concat(accTable, axis=1)\n",
    "    accTable.to_csv('/Users/Alexis/Desktop/MSC_Alexis/analysis/output/results/MVPA/'+subid+'accTable_same_sub.csv')\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_var_same_sub(subid='MSC01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs=['MSC01','MSC02','MSC03','MSC04','MSC05','MSC06','MSC07','MSC08','MSC09','MSC10']\n",
    "for sub in subs:\n",
    "    classify_var_same_sub(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

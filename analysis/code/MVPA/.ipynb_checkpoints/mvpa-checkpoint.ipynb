{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named mvpa2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-574cfec3ed19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#from mvpa2.suite import *\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmvpa2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdebug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SMLR_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named mvpa2"
     ]
    }
   ],
   "source": [
    "#import mvpa2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import sklearn\n",
    "#to manipulate data\n",
    "from mvpa2.datasets import *\n",
    "import scipy.io\n",
    "\n",
    "from mvpa2.suite import *\n",
    "if __debug__:\n",
    "    debug.active.append('SMLR_')\n",
    "    \n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a dict for task\n",
    "matFile = scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/mem/MSC02_parcel_corrmat.mat')\n",
    "#convert to numpy array\n",
    "task_FC=np.array(matFile['parcel_corrmat'])\n",
    "#Index of upper triangle of matrix \n",
    "nrois=333\n",
    "nsess=10\n",
    "task_mask=np.triu_indices(nrois, 1)\n",
    "task_corrlin=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "count=0\n",
    "#loop through all 10 days to reshape correlations into linear form\n",
    "for sess in range(nsess):\n",
    "    tmp=task_FC[:,:,sess]\n",
    "    task_corrlin[count]=tmp[task_mask]\n",
    "    count=count+1\n",
    "\n",
    "#makes a dict for rest\n",
    "matFile = scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/rest/MSC02_parcel_corrmat.mat')\n",
    "#convert to numpy array\n",
    "rest_FC=np.array(matFile['parcel_corrmat'])\n",
    "#Index of upper triangle of matrix \n",
    "nrois=333\n",
    "nsess=10\n",
    "rest_mask=np.triu_indices(nrois, 1)\n",
    "rest_corrlin=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "count=0\n",
    "#loop through all 10 days to reshape correlations into linear form\n",
    "for sess in range(nsess):\n",
    "    tmp=rest_FC[:,:,sess]\n",
    "    rest_corrlin[count]=tmp[rest_mask]\n",
    "    count=count+1\n",
    "    \n",
    "#makes a dict for test task\n",
    "matFile = scipy.io.loadmat('/Users/Alexis/Box/Quest_Backup/MSC/TaskFC/FC_Parcels/motor/MSC02_parcel_corrmat.mat')\n",
    "#convert to numpy array\n",
    "motor_FC=np.array(matFile['parcel_corrmat'])\n",
    "#Index of upper triangle of matrix \n",
    "nrois=333\n",
    "nsess=10\n",
    "test_mask=np.triu_indices(nrois, 1)\n",
    "motor_corrlin=np.empty((nsess, int(nrois*(nrois-1)/2)))\n",
    "count=0\n",
    "#loop through all 10 days to reshape correlations into linear form\n",
    "for sess in range(nsess):\n",
    "    tmp=motor_FC[:,:,sess]\n",
    "    motor_corrlin[count]=tmp[test_mask]\n",
    "    count=count+1\n",
    "#corrlin.shape\n",
    "#task_ds=Dataset(corrlin)\n",
    "#ds.shape\n",
    "#ds.nfeatures\n",
    "#ds.nsamples\n",
    "#create a training dataset from the labeled features\n",
    "task_ds=dataset_wizard(samples=task_corrlin, targets=1)\n",
    "rest_ds=dataset_wizard(samples=rest_corrlin, targets=0)\n",
    "trainpat=vstack((task_ds, rest_ds))\n",
    "\n",
    "#create pattern for testing dataset\n",
    "test_ds=dataset_wizard(samples=motor_corrlin, targets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating SMLR classifier\n",
      "[SMLR_] DBG:                     hstacking 1s for bias\n",
      "[SMLR_] DBG:                     Calling stepwise_regression. Seed 137685067\n"
     ]
    }
   ],
   "source": [
    "#setup SMLR classifier\n",
    "print \"evaluating SMLR classifier\"\n",
    "smlr=SMLR(fit_all_weights=True)\n",
    "#enable saving of estimates used for prediction\n",
    "smlr.ca.enable('estimates')\n",
    "#train with the known points\n",
    "smlr.train(trainpat)\n",
    "#run predictions on test values\n",
    "pre=smlr.predict(test_ds.samples)\n",
    "#caluclate confusion matrix\n",
    "smlr_confusion=ConfusionMatrix(labels=trainpat.UT, targets=test_ds.targets, predictions=pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating linear SVM classifier\n"
     ]
    }
   ],
   "source": [
    "#linear SVM\n",
    "print \"evaluating linear SVM classifier\"\n",
    "lsvm=LinearNuSVMC(probability=1)\n",
    "#save estimates\n",
    "lsvm.ca.enable('estimates')\n",
    "#train with known points\n",
    "lsvm.train(trainpat)\n",
    "#run predictions on test values\n",
    "pre=lsvm.predict(test_ds.samples)\n",
    "#calculate confusion matrix\n",
    "lsvm_confusion=ConfusionMatrix(labels=trainpat.UT, targets=test_ds.targets,predictions=pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating linear SVM classifier with SMLR features\n"
     ]
    }
   ],
   "source": [
    "#train SVM with selected features\n",
    "print \"evaluating linear SVM classifier with SMLR features\"\n",
    "keepInd=(np.abs(smlr.weights).mean(axis=1)!=0)\n",
    "newtrainpat=trainpat[:, keepInd]\n",
    "newtestpat=test_ds[:, keepInd]\n",
    "#train with known points\n",
    "lsvm.train(newtrainpat)\n",
    "#run prediction on test values\n",
    "pre=lsvm.predict(newtestpat.samples)\n",
    "#calculate confusion matrix\n",
    "lsvm_confusion_sparse=ConfusionMatrix(labels=newtrainpat.UT, targets=newtestpat.targets, predictions=pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMLR Percent Correct:\t60% (Retained 36/110556 features)\n",
      "linear-SVM Percent Correct:\t30%\n",
      "linear-SVM Percent Correct (with 18 features from SMLR):\t60%\n"
     ]
    }
   ],
   "source": [
    "print \"SMLR Percent Correct:\\t%g%% (Retained %d/%d features)\" % \\\n",
    "    (smlr_confusion.percent_correct,\n",
    "     (smlr.weights!=0).sum(), np.prod(smlr.weights.shape))\n",
    "print \"linear-SVM Percent Correct:\\t%g%%\" % \\\n",
    "    (lsvm_confusion.percent_correct)\n",
    "print \"linear-SVM Percent Correct (with %d features from SMLR):\\t%g%%\" % \\\n",
    "    (keepInd.sum(), lsvm_confusion_sparse.percent_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 4],\n",
       "       [0, 6]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smlr_confusion.matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 4]\n",
      " [0 6]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

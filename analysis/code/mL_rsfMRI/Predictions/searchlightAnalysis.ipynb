{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "a = np.zeros((5, 5))\n",
    "session=0\n",
    "for name in glob.glob('/Volumes/GRATTONLAB/MSC/MSC_Dconns/Memory/*.dconn.nii'):\n",
    "    print(name)\n",
    "    np.savetxt(name+str(session)+'test.csv',a,delimiter=',')\n",
    "    session=session+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "# Import libraries\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os \n",
    "import time\n",
    "from nilearn import plotting\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "#import nilearn.decoding\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=4)\n",
    "clf= RidgeClassifier()\n",
    "\n",
    "\n",
    "\n",
    "data_file='/Users/Alexis/Desktop/MSC_4k_surfaces/MSC01.L.inflated.4k.surf.gii'\n",
    "data_file = nib.load(data_file)\n",
    "task_data = data_file.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file='/Volumes/GRATTONLAB/MSC/MSC_Dconns/Memory/MSC01_mem_AllSessions_cortex.dconn.nii'\n",
    "data_file = nib.load(data_file)\n",
    "task_data = data_file.get_data()\n",
    "\"\"\"\n",
    "rest_file='/Volumes/GRATTONLAB/MSC/MSC_Dconns/Rest/MSC01_REST_AllSessions_cortex.dconn.nii'\n",
    "rest_file = nib.load(rest_file)\n",
    "rest_data = rest_file.get_data()\n",
    "\n",
    "mask_file='/Users/Alexis/Desktop/BarchSZ/bottomBrainMask.dtseries.nii'\n",
    "mask_file=nib.load(mask_file)\n",
    "mask=mask_file.get_data()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surface based searchlight\n",
    "# ----------------------\n",
    "from nilearn import datasets, surface\n",
    "from sklearn import neighbors\n",
    "from nilearn.decoding.searchlight import search_light\n",
    "\n",
    "#right/left gift template\n",
    "coords,_=surface.load_surf_mesh('/Users/Alexis/Desktop/MSC_4k_surfaces/Conte69.L.inflated.4k_fs_LR.surf.gii')\n",
    "Right_mesh=surface.load_surf_mesh('/Users/Alexis/Desktop/MSC_4k_surfaces/Conte69.R.inflated.4k_fs_LR.surf.gii')\n",
    "\n",
    "\n",
    "\n",
    "radius = 3.\n",
    "nn = neighbors.NearestNeighbors(radius=radius)\n",
    "adjacency = nn.fit(coords).radius_neighbors_graph(coords).tolil()\n",
    "\n",
    "data_file='/Users/Alexis/Desktop/MSC01_ses1.dconn.nii'\n",
    "data_file = nib.load(data_file)\n",
    "task_data = data_file.get_data()\n",
    "\n",
    "fake_rest=data_file.get_data()\n",
    "\n",
    "taskSize=task_data.shape[0]\n",
    "#restSize=rest_data.shape[0]\n",
    "\n",
    "t=np.ones(taskSize, dtype=int)\n",
    "#r=np.zeros(restSize, dtype=int)\n",
    "\n",
    "#x=np.dstack((task_data, rest_data))\n",
    "#y=np.concatenate((t,r))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores = search_light(task_data, t, clf, adjacency, cv=cv, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch a coarse surface of the left hemisphere only for speed\n",
    "fsaverage = datasets.fetch_surf_fsaverage(mesh='fsaverage5')\n",
    "hemi = 'left'\n",
    "\n",
    "# To define the BOLD responses to be included within each searchlight \"sphere\"\n",
    "# we define an adjacency matrix based on the inflated surface vertices such\n",
    "# that nearby surfaces are concatenated within the same searchlight.\n",
    "\n",
    "infl_mesh = fsaverage['infl_' + hemi]\n",
    "coords, _ = surface.load_surf_mesh(infl_mesh)\n",
    "radius = 3.\n",
    "nn = neighbors.NearestNeighbors(radius=radius)\n",
    "adjacency = nn.fit(coords).radius_neighbors_graph(coords).tolil()\n",
    "\n",
    "taskSize=task_data.shape[0]\n",
    "restSize=rest_data.shape[0]\n",
    "\n",
    "t=np.ones(taskSize, dtype=int)\n",
    "r=np.zeros(restSize, dtype=int)\n",
    "\n",
    "#x=np.dstack((task_data, rest_data))\n",
    "y=np.concatenate((t,r))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores = search_light(rest_data, r, clf, adjacency, cv=cv, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_from_cifti(data, axis):\n",
    "    assert isinstance(axis, nib.cifti2.BrainModelAxis)\n",
    "    data = data.T[axis.volume_mask]                          # Assume brainmodels axis is last, move it to front\n",
    "    volmask = axis.volume_mask                               # Which indices on this axis are for voxels?\n",
    "    vox_indices = tuple(axis.voxel[axis.volume_mask].T)      # ([x0, x1, ...], [y0, ...], [z0, ...])\n",
    "    vol_data = np.zeros(axis.volume_shape + data.shape[1:],  # Volume + any extra dimensions\n",
    "                        dtype=data.dtype)\n",
    "    vol_data[vox_indices] = data                             # \"Fancy indexing\"\n",
    "    return nib.Nifti1Image(vol_data, axis.affine)             # Add affine for spatial interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_from_cifti(cifti_data, axes[1]).orthoview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surf_data_from_cifti(data, axis, surf_name):\n",
    "    assert isinstance(axis, nb.cifti2.BrainModelAxis)\n",
    "    for name, data_indices, model in axis.iter_structures():  # Iterates over volumetric and surface structures\n",
    "        if name == surf_name:                                 # Just looking for a surface\n",
    "            data = data.T[data_indices]                       # Assume brainmodels axis is last, move it to front\n",
    "            vtx_indices = model.vertex                        # Generally 1-N, except medial wall vertices\n",
    "            surf_data = np.zeros((vtx_indices.max() + 1,) + data.shape[1:], dtype=data.dtype)\n",
    "            surf_data[vtx_indices] = data\n",
    "            return surf_data\n",
    "    raise ValueError(f\"No structure named {surf_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = nlp.plot_surf(str(data_dir / \"conte69/Conte69.L.inflated.32k_fs_LR.surf.gii\"),\n",
    "                  surf_data_from_cifti(cifti_data, axes[1], 'CIFTI_STRUCTURE_CORTEX_LEFT').mean(axis=1),\n",
    "                  cmap='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_cifti(img):\n",
    "    data = img.get_fdata(dtype=np.float32)\n",
    "    brain_models = img.header.get_axis(1)  # Assume we know this\n",
    "    return (volume_from_cifti(data, brain_models),\n",
    "            surf_data_from_cifti(data, brain_models, \"CIFTI_STRUCTURE_CORTEX_LEFT\"),\n",
    "            surf_data_from_cifti(data, brain_models, \"CIFTI_STRUCTURE_CORTEX_RIGHT\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol, left, right = decompose_cifti(cifti)\n",
    "print(vol.shape, left.shape, right.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores\n",
    "#rest_file.header.get_axis(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchlight = nilearn.decoding.SearchLight(\n",
    "    mask,\n",
    "    radius=5.6, estimator=clf,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=1, cv=cv)\n",
    "searchlight.fit(data_file, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nilearn import datasets\n",
    "from nilearn.image import new_img_like, load_img, get_data\n",
    "\n",
    "# We fetch 2nd subject from haxby datasets (which is default)\n",
    "haxby_dataset = datasets.fetch_haxby()\n",
    "\n",
    "# print basic information on the dataset\n",
    "print('Anatomical nifti image (3D) is located at: %s' % haxby_dataset.mask)\n",
    "print('Functional nifti image (4D) is located at: %s' % haxby_dataset.func[0])\n",
    "\n",
    "fmri_filename = haxby_dataset.func[0]\n",
    "labels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "y = labels['labels']\n",
    "session = labels['chunks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import index_img\n",
    "condition_mask = y.isin(['face', 'house'])\n",
    "\n",
    "fmri_img = index_img(fmri_filename, condition_mask)\n",
    "y, session = y[condition_mask], session[condition_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mask_img = load_img(haxby_dataset.mask)\n",
    "\n",
    "# .astype() makes a copy.\n",
    "process_mask = get_data(mask_img).astype(np.int)\n",
    "picked_slice = 29\n",
    "process_mask[..., (picked_slice + 1):] = 0\n",
    "process_mask[..., :picked_slice] = 0\n",
    "process_mask[:, 30:] = 0\n",
    "process_mask_img = new_img_like(mask_img, process_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=fmri_img.header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make processing parallel\n",
    "# /!\\ As each thread will print its progress, n_jobs > 1 could mess up the\n",
    "#     information output.\n",
    "n_jobs = 1\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "cv = KFold(n_splits=4)\n",
    "clf= RidgeClassifier()\n",
    "import nilearn.decoding\n",
    "# The radius is the one of the Searchlight sphere that will scan the volume\n",
    "searchlight = nilearn.decoding.SearchLight(\n",
    "    mask_img,\n",
    "    radius=5.6, estimator=clf,\n",
    "    n_jobs=n_jobs,\n",
    "    verbose=1, cv=cv)\n",
    "searchlight.fit(fmri_img, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image\n",
    "mean_fmri = image.mean_img(fmri_img)\n",
    "\n",
    "from nilearn.plotting import plot_stat_map, plot_img, show\n",
    "searchlight_img = new_img_like(mean_fmri, searchlight.scores_)\n",
    "\n",
    "# Because scores are not a zero-center test statistics, we cannot use\n",
    "# plot_stat_map\n",
    "plot_img(searchlight_img, bg_img=mean_fmri,\n",
    "         title=\"Searchlight\", display_mode=\"z\", cut_coords=[-9],\n",
    "         vmin=.42, cmap='hot', threshold=.2, black_bg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import surface\n",
    "\n",
    "#test=surface.load_surf_data('/Volumes/GRATTONLAB/MSC/MSC_Dconns/Rest/MSC01_REST_AllSessions_cortex.dconn.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import relevant packages\n",
    "#this script will just start off with doing a simple CV calculation\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import itertools\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import time\n",
    "#using for now; because dconns are all the same size\n",
    "vertex_size=59412\n",
    "scores=np.empty((1,vertex_size))\n",
    "clf=RidgeClassifier()\n",
    "#iterate through each index\n",
    "#lets try a different approach\n",
    "#first load all data\n",
    "#will have to determine if there is a way to declare size based on files found in glob function\n",
    "allTask=np.empty((vertex_size,vertex_size,10))\n",
    "allRest=np.empty((vertex_size,vertex_size,10))\n",
    "\n",
    "\n",
    "allTask.shape\n",
    "\n",
    "import numpy as np\n",
    "test=np.genfromtxt('~/Desktop/MSC01_sess9.dconn.nii1first.csv',delimiter=',')\n",
    "\n",
    "\n",
    "test=np.genfromtxt('/Users/Alexis/Desktop/CV_mem_MSC01.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import reshape\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "thisDir = os.path.expanduser('~/Desktop/MSC_Alexis/analysis/')\n",
    "dataDir = thisDir + 'data/mvpa_data/'\n",
    "restFC=reshape.matFiles(dataDir+'rest/corrmats_timesplit/fourths/MSC01_parcel_corrmat.mat') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "restFC=np.reshape(restFC,(10,4,55278))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=np.reshape(restFC,(-1,55278))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 55278)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import permuteROI\n",
    "import numpy as np\n",
    "res=permuteROI.modelAll_byRow('MSC03')\n",
    "\n",
    "res.tofile('/Users/Alexis/Desktop/MSC_Alexis/analysis/output/results/permutation/ALL/MSC03_Row.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "#import other python scripts for further anlaysis\n",
    "import reshape\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "#import results\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Initialization of directory information:\n",
    "thisDir = os.path.expanduser('~/Desktop/MSC_Alexis/analysis/')\n",
    "dataDir = thisDir + 'data/mvpa_data/'\n",
    "def classifyCV(sub, task):\n",
    "    \"\"\"\n",
    "    Classifying same subjects (CV) along the same task\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    dfCV : DataFrame\n",
    "        Dataframe consisting of average accuracy across all subjects\n",
    "\n",
    "    \"\"\"\n",
    "    clf=RidgeClassifier()\n",
    "\n",
    "    taskFC=reshape.matFiles(dataDir+task+'/'+sub+'_parcel_corrmat.mat')\n",
    "    restFC=reshape.matFiles(dataDir+'rest/'+sub+'_parcel_corrmat.mat')\n",
    "    folds=taskFC.shape[0]\n",
    "    x_train, y_train=reshape.concateFC(taskFC, restFC)\n",
    "    output = cross_validate(clf, x_train, y_train, cv=folds, scoring = 'accuracy', return_estimator =True)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=classifyCV('MSC01','mem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score for estimator 0:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RidgeClassifier' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3373d219d8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'estimator'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Features sorted by their score for estimator {}:\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     feature_importances = pd.DataFrame(estimator.feature_importances_,\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                         columns=['importance']).sort_values('importance', ascending=False)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RidgeClassifier' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "for idx,estimator in enumerate(output['estimator']):\n",
    "    print(\"Features sorted by their score for estimator {}:\".format(idx))\n",
    "    feature_importances = pd.DataFrame(estimator.feature_importances_,                     \n",
    "                                        columns=['importance']).sort_values('importance', ascending=False)\n",
    "    print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RidgeClassifier(),\n",
       " RidgeClassifier(),\n",
       " RidgeClassifier(),\n",
       " RidgeClassifier(),\n",
       " RidgeClassifier(),\n",
       " RidgeClassifier(),\n",
       " RidgeClassifier(),\n",
       " RidgeClassifier(),\n",
       " RidgeClassifier(),\n",
       " RidgeClassifier()]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_validate\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "#import other python scripts for further anlaysis\n",
    "import reshape\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "#import results\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Initialization of directory information:\n",
    "thisDir = os.path.expanduser('~/Desktop/MSC_Alexis/analysis/')\n",
    "dataDir = thisDir + 'data/mvpa_data/'\n",
    "splitDict=dict([('MSC01',10),('MSC02',10),('MSC03',8),('MSC04',10),('MSC05',10),('MSC06',9),('MSC07',9),('MSC10',10)])\n",
    "\n",
    "def modelAll(train_sub):\n",
    "    \"\"\"\n",
    "    Preparing machine learning model with appropriate data\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    train_sub : str\n",
    "            Subject name for training\n",
    "    test_sub : str\n",
    "            Subject name for testing\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    total_score : float\n",
    "            Average accuracy of all folds\n",
    "\n",
    "    \"\"\"\n",
    "    session=splitDict[train_sub]\n",
    "    split=np.empty((session, 55278))\n",
    "    count=0\n",
    "    clf=RidgeClassifier()\n",
    "    df=pd.DataFrame()\n",
    "    #train sub\n",
    "    memFC=reshape.permROI(dataDir+'mem/'+train_sub+'_parcel_corrmat.mat')\n",
    "    semFC=reshape.permROI(dataDir+'semantic/'+train_sub+'_parcel_corrmat.mat')\n",
    "    glassFC=reshape.permROI(dataDir+'glass/'+train_sub+'_parcel_corrmat.mat')\n",
    "    motFC=reshape.permROI(dataDir+'motor/'+train_sub+'_parcel_corrmat.mat')\n",
    "    restFC=reshape.permROI(dataDir+'rest/corrmats_timesplit/fourths/'+train_sub+'_parcel_corrmat.mat') #keep tasks seperated in order to collect the right amount of days\n",
    "    restFC=np.reshape(restFC,(10,4,55278)) #reshape to gather correct days\n",
    "    loo = LeaveOneOut()\n",
    "    fw=np.empty([memFC.shape[0],55278])\n",
    "    for train_index, test_index in loo.split(split):\n",
    "        memtrain=memFC[train_index]\n",
    "        semtrain=semFC[train_index]\n",
    "        mottrain=motFC[train_index]\n",
    "        glatrain=glassFC[train_index]\n",
    "        Xtrain_task=np.concatenate((memtrain,semtrain,mottrain,glatrain))\n",
    "        Xtrain_rest=restFC[train_index,:,:]\n",
    "        Xtrain_rest=np.reshape(Xtrain_rest,(-1,55278))\n",
    "        ytrain_task = np.ones(Xtrain_task.shape[0], dtype = int)\n",
    "        ytrain_rest=np.zeros(Xtrain_rest.shape[0], dtype=int)\n",
    "        X_tr=np.concatenate((Xtrain_task, Xtrain_rest))\n",
    "        y_tr = np.concatenate((ytrain_task,ytrain_rest))\n",
    "        clf.fit(X_tr,y_tr)\n",
    "        features = clf.coef_[0]\n",
    "        fw[count]=features\n",
    "        count=count+1\n",
    "    fwAve=fw.mean(axis=0)\n",
    "    results=np.empty((333))\n",
    "    for rowID, null in enumerate(results):\n",
    "        indices=reshape.getIndices()\n",
    "        index=indices.index\n",
    "        condition=indices['level_1']==rowID\n",
    "        ROI=index[condition]\n",
    "        ROI_list=ROI.tolist()\n",
    "        tmp=fwAve[ROI_list]\n",
    "        row=np.sum(np.abs(tmp))\n",
    "        results[rowID]=row\n",
    "    return fw, results\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "subList=['MSC01','MSC02','MSC03','MSC04','MSC05','MSC06','MSC07','MSC10']\n",
    "Parcel_params = reshape.loadParcelParams('Gordon333','/Users/Alexis/Desktop/MSC_Alexis/analysis/data/Parcel_info/')\n",
    "roi_sort = np.squeeze(Parcel_params['roi_sort'])\n",
    "for train_sub in subList:\n",
    "    fw, results=modelAll(train_sub)\n",
    "    data={'acc':results,'roi':roi_sort}\n",
    "    df=pd.DataFrame(data)\n",
    "    df.sort_values(by='roi',inplace=True) \n",
    "    array=df['acc'].to_numpy()#convert back to numpy array for saving to make plots \n",
    "    array.tofile('/Users/Alexis/Desktop/MSC_Alexis/analysis/output/results/acc/ALL/subs/'+train_sub+'.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw, results=modelAll('MSC05')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fwSize=fw.shape[0]\n",
    "Parcel_params = reshape.loadParcelParams('Gordon333','/Users/Alexis/Desktop/MSC_Alexis/analysis/data/Parcel_info/')\n",
    "roi_sort = np.squeeze(Parcel_params['roi_sort'])\n",
    "for i in range(fwSize):\n",
    "    fold=fw[i]\n",
    "    results=np.empty((333))\n",
    "    for rowID, null in enumerate(results):\n",
    "        indices=reshape.getIndices()\n",
    "        index=indices.index\n",
    "        condition=indices['level_1']==rowID\n",
    "        ROI=index[condition]\n",
    "        ROI_list=ROI.tolist()\n",
    "        tmp=fold[ROI_list]\n",
    "        row=np.sum(np.abs(tmp))\n",
    "        results[rowID]=row\n",
    "    data={'acc':results,'roi':roi_sort}\n",
    "    df=pd.DataFrame(data)\n",
    "    df.sort_values(by='roi',inplace=True) \n",
    "    array=df['acc'].to_numpy()#convert back to numpy array for saving to make plots \n",
    "    array.tofile('/Users/Alexis/Desktop/MSC_Alexis/analysis/output/results/acc/ALL/foldMSC05/fold'+str(i)+'.csv', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 55278)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motFC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08944552486542898"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8555e9c3ab81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwAve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodelAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MSC01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfwAve\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'roi'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mroi_sort\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#take the sum of absolute value per row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         ]\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "data={'acc':fwAve,'roi':roi_sort}\n",
    "df=pd.DataFrame(data)\n",
    "df.sort_values(by='roi',inplace=True) #take the sum of absolute value per row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_sort.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with 14808\n",
      "Finished with 10824\n",
      "Finished with 8736\n",
      "Finished with 4620\n",
      "Finished with 5264\n",
      "Finished with 3151\n",
      "Finished with 494\n",
      "Finished with 4060\n",
      "Finished with 2375\n",
      "Finished with 316\n",
      "Finished with 564\n",
      "Finished with 45\n",
      "Finished with 21\n"
     ]
    }
   ],
   "source": [
    "import quest_nullNet as qn\n",
    "qn.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with unassign\n",
      "Finished with default\n",
      "Finished with visual\n",
      "Finished with fp\n",
      "Finished with dan\n",
      "Finished with van\n",
      "Finished with salience\n",
      "Finished with co\n",
      "Finished with sm\n",
      "Finished with sm-lat\n",
      "Finished with auditory\n",
      "Finished with pmn\n",
      "Finished with pon\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import featSelection as fs\n",
    "SS_df=pd.DataFrame()\n",
    "import os\n",
    "import sys\n",
    "import reshape\n",
    "from statistics import mean\n",
    "#import other python scripts for further anlaysis\n",
    "# Initialization of directory information:\n",
    "#thisDir = os.path.expanduser('~/Desktop/MSC_Alexis/analysis/')\n",
    "thisDir = os.path.expanduser('~/Desktop/MSC_Alexis/analysis/')\n",
    "dataDir = thisDir + 'data/mvpa_data/'\n",
    "outDir = thisDir + 'output/results/subNetwork/'\n",
    "netRoi=dict([('unassign',14808),('default', 10824),('visual',8736),('fp', 4620),('dan',5264),('van',3151),('salience', 494),('co', 4060),('sm', 2375),('sm-lat', 316),('auditory', 564),('pmn',45),('pon',21)])\n",
    "\n",
    "\n",
    "for i in netRoi:\n",
    "    #generate a new index\n",
    "    idx=netRoi[i]\n",
    "    SS=fs.modelAll(i)\n",
    "    SS['feature']=idx\n",
    "    SS['Network']=i\n",
    "    SS_df=pd.concat([SS_df,SS])\n",
    "    print('Finished with '+i)\n",
    "SS_df.to_csv(outDir+'ALL/acc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

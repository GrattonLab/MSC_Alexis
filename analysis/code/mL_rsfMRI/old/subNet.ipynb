{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "#import other python scripts for further anlaysis\n",
    "import classification\n",
    "# Initialization of directory information:\n",
    "thisDir = os.path.expanduser('~/Desktop/MSC_Alexis/analysis/')\n",
    "#dataDir = thisDir + 'data/mvpa_data/tmask_all/'\n",
    "#outDir = thisDir + 'output/mLmax/results/ridge/subNetwork/'\n",
    "#dataDir = thisDir + 'data/mvpa_data/'\n",
    "#outDir = thisDir + 'output/subNetwork/'\n",
    "dataDir = thisDir + 'data/mvpa_data/tmask_min/'\n",
    "outDir = thisDir + 'output/mLmin/results/ridge/subNetwork/'\n",
    "# Subjects and tasks\n",
    "taskList=['mixed', 'motor','mem']\n",
    "subList=['MSC01','MSC02','MSC03','MSC04','MSC05','MSC06','MSC07','MSC10']\n",
    "#subList=['MSC01','MSC02','MSC04','MSC05','MSC10']\n",
    "#all possible combinations of subs and tasks\n",
    "subsComb=(list(itertools.permutations(subList, 2)))\n",
    "tasksComb=(list(itertools.permutations(taskList, 2)))\n",
    "#DS combination\n",
    "DSvars=list(itertools.product(list(subsComb),list(taskList)))\n",
    "##SS combination\n",
    "SSvars=list(itertools.product(list(subList),list(tasksComb)))\n",
    "#BS combination\n",
    "BSvars=list(itertools.product(list(subsComb),list(tasksComb)))\n",
    "\n",
    "\n",
    "\"\"\" run_prediction initializes what type of analysis you would like to do\n",
    "and what classifier you would like to use. For now classifier options are svm:linear svm, logreg: logistic\n",
    "regression, and ridge:ridge regression. Analysis is the type of analysis you wanted\n",
    "to run. DS--different subject same task; SS--same subject different task;\n",
    "BS--different subject different task. Each analysis will concatenate across\n",
    "subjects and make a dataframe. If FW is true will collect all necessary feature weights and plot or save then\n",
    "into the appropriate format. \"\"\"\n",
    "def classifyDS(classifier, analysis, network):\n",
    "    acc_scores_per_task=[]\n",
    "    tmp_df=pd.DataFrame(DSvars, columns=['sub','task'])\n",
    "    dfDS=pd.DataFrame()\n",
    "    dfDS[['train_sub','test_sub']]=pd.DataFrame(tmp_df['sub'].tolist())\n",
    "    dfDS['task']=tmp_df['task']\n",
    "    for index, row in dfDS.iterrows():\n",
    "        score=model(classifier, analysis, network, train_sub=row['train_sub'], test_sub=row['test_sub'], train_task=row['task'], test_task=row['task'])\n",
    "        acc_scores_per_task.append(score)\n",
    "    dfDS['acc']=acc_scores_per_task\n",
    "    #dfDS.to_csv(outDir+network+'/results/'+classifier+'/acc/'+analysis+'/acc.csv')\n",
    "    dfDS.to_csv(outDir+network+'/'+analysis+'/acc.csv')\n",
    "    statsACC(dfDS, classifier, analysis, network)\n",
    "def classifySS(classifier,analysis, network):\n",
    "    acc_scores_per_task=[]\n",
    "    tmp_df=pd.DataFrame(SSvars, columns=['sub','task'])\n",
    "    dfSS=pd.DataFrame()\n",
    "    dfSS[['train_task','test_task']]=pd.DataFrame(tmp_df['task'].tolist())\n",
    "    dfSS['sub']=tmp_df['sub']\n",
    "    for index, row in dfSS.iterrows():\n",
    "        score=model(classifier, analysis, network, train_sub=row['sub'], test_sub=row['sub'], train_task=row['train_task'], test_task=row['test_task'])\n",
    "        acc_scores_per_task.append(score)\n",
    "    dfSS['acc']=acc_scores_per_task\n",
    "    #save accuracy\n",
    "    #dfSS.to_csv(outDir+network+'/results/'+classifier+'/acc/'+analysis+'/acc.csv')\n",
    "    dfSS.to_csv(outDir+network+'/'+analysis+'/acc.csv')\n",
    "    statsACC(dfSS, classifier, analysis, network)\n",
    "def classifyBS(classifier, analysis, network):\n",
    "    acc_scores_per_task=[]\n",
    "    tmp_df=pd.DataFrame(BSvars, columns=['sub','task'])\n",
    "    dfBS=pd.DataFrame()\n",
    "    dfBS[['train_task','test_task']]=pd.DataFrame(tmp_df['task'].tolist())\n",
    "    dfBS[['train_sub', 'test_sub']]=pd.DataFrame(tmp_df['sub'].tolist())\n",
    "    for index, row in dfBS.iterrows():\n",
    "        score=model(classifier, analysis, network, train_sub=row['train_sub'], test_sub=row['test_sub'], train_task=row['train_task'], test_task=row['test_task'])\n",
    "        acc_scores_per_task.append(score)\n",
    "    dfBS['acc']=acc_scores_per_task\n",
    "    #results.plotACC(dfBS, classifier, analysis)\n",
    "    #results.statsACC(dfBS, classifier, analysis, 'fp_co')\n",
    "    #results.boxACC(dfBS, classifier, analysis)\n",
    "    #save accuracy\n",
    "    #dfBS.to_csv(outDir+network+'/results/'+classifier+'/acc/'+analysis+'/acc.csv')\n",
    "    dfBS.to_csv(outDir+network+'/'+analysis+'/acc.csv')\n",
    "    statsACC(dfBS, classifier, analysis, network)\n",
    "\n",
    "def model(classifier, analysis, network, train_sub, test_sub, train_task, test_task):\n",
    "    if classifier=='SVC':\n",
    "        clf=LinearSVC(max_iter=10000, dual=False)\n",
    "    elif classifier=='logReg':\n",
    "        clf=LogisticRegression(solver = 'lbfgs', max_iter=10000)\n",
    "    elif classifier=='ridge':\n",
    "        clf=RidgeClassifier(max_iter=10000)\n",
    "    else:\n",
    "        print('Error: You didnt specify what classifier')\n",
    "    taskFC=classification.subNets(dataDir+train_task+'/'+train_sub+'_parcel_corrmat.mat', network)\n",
    "    restFC=classification.subNets(dataDir+'rest/'+train_sub+'_parcel_corrmat.mat', network)\n",
    "    #if your subs are the same\n",
    "    if train_sub==test_sub:\n",
    "        test_taskFC=classification.subNets(dataDir+test_task+'/'+test_sub+'_parcel_corrmat.mat',network)\n",
    "        ACCscores=CV_folds(clf, analysis, taskFC, restFC, test_taskFC, restFC)\n",
    "    else:\n",
    "        test_taskFC=classification.subNets(dataDir+test_task+'/'+test_sub+'_parcel_corrmat.mat',network)\n",
    "        test_restFC=classification.subNets(dataDir+'rest/'+test_sub+'_parcel_corrmat.mat',network)\n",
    "        ACCscores=CV_folds(clf, analysis, taskFC, restFC, test_taskFC, test_restFC)\n",
    "    return ACCscores\n",
    "#Calculate acc of cross validation within sub within task\n",
    "def classifyCV(classifier, analysis, network):\n",
    "    avg_CV=[]\n",
    "    if classifier=='SVC':\n",
    "        clf=LinearSVC(max_iter=10000, dual=False)\n",
    "    elif classifier=='logReg':\n",
    "        clf=LogisticRegression(solver = 'lbfgs', max_iter=10000)\n",
    "    elif classifier=='ridge':\n",
    "        clf=RidgeClassifier(max_iter=10000)\n",
    "    else:\n",
    "        print('invalid classifier')\n",
    "    for task in taskList:\n",
    "        acc_scores_per_task=[]\n",
    "        cvTable=[]\n",
    "        for sub in subList:\n",
    "            taskFC=classification.subNets(dataDir+task+'/'+sub+'_parcel_corrmat.mat',network)\n",
    "            restFC=classification.subNets(dataDir+'rest/'+sub+'_parcel_corrmat.mat',network)\n",
    "            folds=taskFC.shape[0]\n",
    "            x_train, y_train=classification.concateFC(taskFC, restFC)\n",
    "            CVscores=cross_val_score(clf, x_train, y_train, cv=folds)\n",
    "            mu=CVscores.mean()\n",
    "            acc_scores_per_task.append(mu)\n",
    "            cv_tmp_df=pd.DataFrame({sub:CVscores})\n",
    "            cvTable.append(cv_tmp_df)\n",
    "    #acc per fold per sub\n",
    "        tmp_df=pd.DataFrame({'sub':subList, task:acc_scores_per_task}).set_index('sub')\n",
    "        avg_CV.append(tmp_df)\n",
    "        cvTable=pd.concat(cvTable, axis=1)\n",
    "    #saving cv per folds if debugging\n",
    "        #cvTable.to_csv(outDir+network+'/results/'+classifier+'/acc/'+analysis+'/'+task+'_cvTable_folds.csv')\n",
    "        cvTable.to_csv(outDir+network+'/'+analysis+'/'+task+'_cvTable_folds.csv')\n",
    "    #average acc per sub per tasks\n",
    "    df=pd.concat(avg_CV, axis=1)\n",
    "    #df.to_csv(outDir+network+'/results/'+classifier+'/acc/'+analysis+'/acc.csv')\n",
    "    df.to_csv(outDir+network+'/'+analysis+'/acc.csv')\n",
    "    statsACC(df, classifier, analysis, network)\n",
    "def CV_folds(clf, analysis, taskFC, restFC, test_taskFC, test_restFC):\n",
    "    loo = LeaveOneOut()\n",
    "    taskSize=taskFC.shape[0]\n",
    "    restSize=restFC.shape[0]\n",
    "    t = np.ones(taskSize, dtype = int)\n",
    "    r=np.zeros(restSize, dtype=int)\n",
    "    \n",
    "    if analysis=='SS':\n",
    "        df=pd.DataFrame()\n",
    "        acc_score=[]\n",
    "        for train_index, test_index in loo.split(taskFC):\n",
    "            Xtrain_rest, Xtest_rest=restFC[train_index], restFC[test_index]\n",
    "            Xtrain_task=taskFC[train_index]\n",
    "            ytrain_rest=r[train_index]\n",
    "            ytrain_task=t[train_index]\n",
    "            X_tr=np.concatenate((Xtrain_task, Xtrain_rest))\n",
    "            y_tr = np.concatenate((ytrain_task,ytrain_rest))\n",
    "            #implementing standardization\n",
    "            scaler = preprocessing.StandardScaler().fit(X_tr)\n",
    "            scaler.transform(X_tr)\n",
    "            clf.fit(X_tr,y_tr)\n",
    "            tmpdf=pd.DataFrame()\n",
    "            acc_scores_per_fold=[]\n",
    "            for t_index, te_index in loo.split(test_taskFC):\n",
    "                Xtest_task=test_taskFC[te_index]\n",
    "                X_Test = np.concatenate((Xtest_task, Xtest_rest))\n",
    "                y_Test = np.array([1, 0])\n",
    "                #test set\n",
    "                #standardization\n",
    "                scaler.transform(X_Test)\n",
    "                clf.predict(X_Test)\n",
    "                #Get accuracy of model\n",
    "                ACCscores=clf.score(X_Test,y_Test)\n",
    "                acc_scores_per_fold.append(ACCscores)\n",
    "            tmpdf['inner_fold']=acc_scores_per_fold\n",
    "            score=tmpdf['inner_fold'].mean()\n",
    "            acc_score.append(score)\n",
    "        df['outer_fold']=acc_score\n",
    "        total_score=df['outer_fold'].mean()\n",
    "    else:\n",
    "        df=pd.DataFrame()\n",
    "        acc_score=[]\n",
    "        #fold each training set\n",
    "        for train_index, test_index in loo.split(taskFC):\n",
    "            Xtrain_rest=restFC[train_index]\n",
    "            Xtrain_task=taskFC[train_index]\n",
    "            ytrain_rest=r[train_index]\n",
    "            ytrain_task=t[train_index]\n",
    "            X_tr=np.concatenate((Xtrain_task, Xtrain_rest))\n",
    "            y_tr = np.concatenate((ytrain_task,ytrain_rest))\n",
    "            #implement standardization\n",
    "            scaler = preprocessing.StandardScaler().fit(X_tr)\n",
    "            scaler.transform(X_tr)\n",
    "            clf.fit(X_tr,y_tr)\n",
    "            tmpdf=pd.DataFrame()\n",
    "            acc_scores_per_fold=[]\n",
    "            #fold each testing set\n",
    "            for t_index, te_index in loo.split(test_taskFC):\n",
    "                Xtest_rest=test_restFC[te_index]\n",
    "                Xtest_task=test_taskFC[te_index]\n",
    "                X_te=np.concatenate((Xtest_task, Xtest_rest))\n",
    "                y_te=np.array([1, 0])\n",
    "                #test set\n",
    "                #standardization\n",
    "                scaler.transform(X_te)\n",
    "                clf.predict(X_te)\n",
    "                #Get accuracy of model\n",
    "                ACCscores=clf.score(X_te,y_te)\n",
    "                acc_scores_per_fold.append(ACCscores)\n",
    "            tmpdf['inner_fold']=acc_scores_per_fold\n",
    "            score=tmpdf['inner_fold'].mean()\n",
    "            acc_score.append(score)\n",
    "        df['outer_fold']=acc_score\n",
    "        total_score=df['outer_fold'].mean()\n",
    "\n",
    "    return total_score\n",
    "\n",
    "def statsACC(df, classifier, analysis, network):\n",
    "    if analysis=='CV':\n",
    "        print('cross validation stats')\n",
    "        mu=df.mean()\n",
    "        sd=df.std()\n",
    "        stats=pd.DataFrame({'Mean':mu, 'Std':sd})\n",
    "        #stats.to_csv(outDir+network+'/results/'+classifier+'/acc/'+analysis+'/stats.csv', index=True)\n",
    "        stats.to_csv(outDir+network+'/'+analysis+'/stats.csv', index=True)\n",
    "    elif analysis=='SS':\n",
    "        print('same sub stats')\n",
    "        df.drop(['sub'], axis=1, inplace=True)\n",
    "        stats=df.groupby(['test_task', 'train_task']).mean()\n",
    "        stats.rename(columns={'acc':'Mean'}, inplace=True)\n",
    "        sd=df.groupby(['test_task', 'train_task']).std()\n",
    "        stats['Std']=sd['acc']\n",
    "        stats.reset_index(inplace=True)\n",
    "        #stats.to_csv(outDir+network+'/results/'+classifier+'/acc/'+analysis+'/stats.csv', index=True)\n",
    "        stats.to_csv(outDir+network+'/'+analysis+'/stats.csv', index=True)\n",
    "    elif analysis=='DS':\n",
    "        print('diff sub stats')\n",
    "        df.drop(['train_sub', 'test_sub'], axis=1, inplace=True)\n",
    "        stats=df.groupby('task').mean()\n",
    "        stats.rename(columns={'acc':'Mean'}, inplace=True)\n",
    "        sd=df.groupby('task').std()\n",
    "        stats['Std']=sd['acc']\n",
    "        #stats.to_csv(outDir+network+'/results/'+classifier+'/acc/'+analysis+'/stats.csv', index=True)\n",
    "        stats.to_csv(outDir+network+'/'+analysis+'/stats.csv', index=True)\n",
    "    elif analysis=='BS':\n",
    "        print('diff sub diff task stats')\n",
    "        df.drop(['train_sub', 'test_sub'], axis=1, inplace=True)\n",
    "        stats=df.groupby(['test_task', 'train_task']).mean()\n",
    "        stats.rename(columns={'acc':'Mean'}, inplace=True)\n",
    "        sd=df.groupby(['test_task', 'train_task']).std()\n",
    "        stats['Std']=sd['acc']\n",
    "        stats.reset_index(inplace=True)\n",
    "        #stats.to_csv(outDir+network+'/results/'+classifier+'/acc/'+analysis+'/stats.csv', index=True)\n",
    "        stats.to_csv(outDir+network+'/'+analysis+'/stats.csv', index=True)\n",
    "    else:\n",
    "        print('skipping stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running for network unassign\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network default\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network visual\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network fp\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network dan\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network van\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network salience\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network co\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network sm\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network sm-lat\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network auditory\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network pmn\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n",
      "Now running for network pon\n",
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n"
     ]
    }
   ],
   "source": [
    "networkList=['unassign',\n",
    "    'default',\n",
    "    'visual',\n",
    "    'fp',\n",
    "    'dan',\n",
    "    'van',\n",
    "    'salience',\n",
    "    'co',\n",
    "    'sm',\n",
    "    'sm-lat',\n",
    "    'auditory',\n",
    "    'pmn',\n",
    "    'pon']\n",
    "#analysisList=['DS', 'SS', 'BS','CV']\n",
    "#classifierList=['SVC', 'logReg','ridge']\n",
    "for network in networkList:\n",
    "    print('Now running for network '+network)\n",
    "    classifyCV('ridge', 'CV', network)\n",
    "    print(\"Finished CV\")\n",
    "    classifyDS('ridge', 'DS', network)\n",
    "    print(\"Finished DS\")\n",
    "    classifySS('ridge', 'SS', network)\n",
    "    print(\"Finished SS\")\n",
    "    classifyBS('ridge', 'BS', network)\n",
    "    print(\"Finished BS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation stats\n",
      "Finished CV\n",
      "diff sub stats\n",
      "Finished DS\n",
      "same sub stats\n",
      "Finished SS\n",
      "diff sub diff task stats\n",
      "Finished BS\n"
     ]
    }
   ],
   "source": [
    "classifyCV('ridge', 'CV', 'unassign')\n",
    "print(\"Finished CV\")\n",
    "classifyDS('ridge', 'DS', 'unassign')\n",
    "print(\"Finished DS\")\n",
    "classifySS('ridge', 'SS', 'unassign')\n",
    "print(\"Finished SS\")\n",
    "classifyBS('ridge', 'BS', 'unassign')\n",
    "print(\"Finished BS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

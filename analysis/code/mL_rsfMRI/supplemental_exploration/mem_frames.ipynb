{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import classification\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import classification\n",
    "#import other python scripts for further anlaysis\n",
    "#import reshape\n",
    "#import results\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Initialization of directory information:\n",
    "thisDir = os.path.expanduser('~/Desktop/MSC_Alexis/analysis/')\n",
    "#using less conservative fc matrices\n",
    "dataDir = thisDir + 'data/mvpa_data/'\n",
    "framesDir = thisDir + 'data/mvpa_data/tmask_frames/'\n",
    "outDir = thisDir + 'output/mLmin/results/ridge/frames/'\n",
    "\n",
    "#dataDir = thisDir + 'data/mvpa_data/'\n",
    "#outDir = thisDir + 'output/mL/'\n",
    "# Subjects and tasks\n",
    "taskList=['mixed', 'motor','mem']\n",
    "#taskList=['glass','semantic', 'motor','mem']\n",
    "#subList=['MSC01','MSC02','MSC03','MSC04','MSC05','MSC06','MSC07','MSC10']\n",
    "subList=['MSC05','MSC06','MSC07']\n",
    "#all possible combinations of subs and tasks\n",
    "subsComb=(list(itertools.permutations(subList, 2)))\n",
    "tasksComb=(list(itertools.permutations(taskList, 2)))\n",
    "#DS combination\n",
    "DSvars=list(itertools.product(list(subsComb),list(taskList)))\n",
    "##SS combination\n",
    "SSvars=list(itertools.product(list(subList),list(tasksComb)))\n",
    "#BS combination\n",
    "BSvars=list(itertools.product(list(subsComb),list(tasksComb)))\n",
    "\n",
    "#only training on memory \n",
    "#frames\n",
    "frameList=[5,10,15,20,25,30,40,50,60,70,80,90,100,125,150,175,200,225,250,275,300,325,350];\n",
    "\n",
    "def calc_frames():\n",
    "    CV_acc=[]\n",
    "    SS_acc=[]\n",
    "    DS_acc=[]\n",
    "    BS_acc=[]\n",
    "    for f in frameList:\n",
    "        CV_acc.append(classifyCV(f))\n",
    "        SS_acc.append(classifySS(f))\n",
    "        DS_acc.append(classifyDS(f))\n",
    "        BS_acc.append(classifyBS(f))\n",
    "    tmp_CV=pd.DataFrame({'Frames':frameList, 'Acc':CV_acc,'Analysis':'CV'})\n",
    "    tmp_SS=pd.DataFrame({'Frames':frameList, 'Acc':SS_acc,'Analysis':'SS'})\n",
    "    tmp_DS=pd.DataFrame({'Frames':frameList, 'Acc':DS_acc,'Analysis':'DS'})\n",
    "    tmp_BS=pd.DataFrame({'Frames':frameList, 'Acc':BS_acc,'Analysis':'BS'})\n",
    "    df_all=[tmp_CV,tmp_SS,tmp_DS,tmp_BS]\n",
    "    allFrames=pd.concat(df_all)\n",
    "    allFrames.to_csv(outDir+'allFrames.csv')\n",
    "    \n",
    "def classifyDS(frames):\n",
    "    \"\"\"\n",
    "    Classifying different subjects (DS) along the same task\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    classifier : str\n",
    "            The statistical method used for classification\n",
    "    analysis : str\n",
    "            The type of analysis to be conducted\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    dfDS : DataFrame\n",
    "        Dataframe consisting of average accuracy across all subjects\n",
    "\n",
    "    \"\"\"\n",
    "    acc_scores_per_task=[]\n",
    "    tmp_df=pd.DataFrame(DSvars, columns=['sub','task'])\n",
    "    dfDS=pd.DataFrame()\n",
    "    dfDS[['train_sub','test_sub']]=pd.DataFrame(tmp_df['sub'].tolist())\n",
    "    dfDS['task']=tmp_df['task']\n",
    "    for index, row in dfDS.iterrows():\n",
    "        score=model(frames,'DS', train_sub=row['train_sub'], test_sub=row['test_sub'], train_task='mem', test_task=row['task'])\n",
    "        acc_scores_per_task.append(score)\n",
    "    dfDS['acc']=acc_scores_per_task\n",
    "    DS_acc=statsACC(dfDS, 'DS')\n",
    "    return DS_acc\n",
    "    \n",
    "def classifySS(frames):\n",
    "    \"\"\"\n",
    "    Classifying the same subject (SS) along a different task\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    classifier : str\n",
    "            The statistical method used for classification\n",
    "    analysis : str\n",
    "            The type of analysis to be conducted\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    dfSS : DataFrame\n",
    "        Dataframe consisting of average accuracy across all subjects\n",
    "\n",
    "    \"\"\"\n",
    "    acc_scores_per_task=[]\n",
    "    tmp_df=pd.DataFrame(SSvars, columns=['sub','task'])\n",
    "    dfSS=pd.DataFrame()\n",
    "    dfSS[['train_task','test_task']]=pd.DataFrame(tmp_df['task'].tolist())\n",
    "    dfSS['sub']=tmp_df['sub']\n",
    "    for index, row in dfSS.iterrows():\n",
    "        score=model(frames,'SS', train_sub=row['sub'], test_sub=row['sub'], train_task='mem', test_task=row['test_task'])\n",
    "        acc_scores_per_task.append(score)\n",
    "    dfSS['acc']=acc_scores_per_task\n",
    "    SS_acc=statsACC(dfSS, 'SS')\n",
    "    return SS_acc\n",
    "def classifyBS(frames):\n",
    "    \"\"\"\n",
    "    Classifying different subjects (BS) along different tasks\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    classifier : str\n",
    "            The statistical method used for classification\n",
    "    analysis : str\n",
    "            The type of analysis to be conducted\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    dfBS : DataFrame\n",
    "        Dataframe consisting of average accuracy across all subjects\n",
    "\n",
    "    \"\"\"\n",
    "    acc_scores_per_task=[]\n",
    "    tmp_df=pd.DataFrame(BSvars, columns=['sub','task'])\n",
    "    dfBS=pd.DataFrame()\n",
    "    dfBS[['train_task','test_task']]=pd.DataFrame(tmp_df['task'].tolist())\n",
    "    dfBS[['train_sub', 'test_sub']]=pd.DataFrame(tmp_df['sub'].tolist())\n",
    "    for index, row in dfBS.iterrows():\n",
    "        score=model(frames,'BS', train_sub=row['train_sub'], test_sub=row['test_sub'], train_task='mem', test_task=row['test_task'])\n",
    "        acc_scores_per_task.append(score)\n",
    "    dfBS['acc']=acc_scores_per_task\n",
    "    BS_acc=statsACC(dfBS, 'BS')\n",
    "    return BS_acc\n",
    "\n",
    "\n",
    "def classifyCV(frames):\n",
    "    \"\"\"\n",
    "    Classifying same subjects (CV) along the same task\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    classifier : str\n",
    "            The statistical method used for classification\n",
    "    analysis : str\n",
    "            The type of analysis to be conducted\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    dfCV : DataFrame\n",
    "        Dataframe consisting of average accuracy across all subjects\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    clf=RidgeClassifier()\n",
    "    cvTable=[]\n",
    "    acc_scores=[]\n",
    "    for sub in subList:\n",
    "        taskFC=classification.matFiles(framesDir+'mem/'+str(frames)+'/'+sub+'_parcel_corrmat.mat')\n",
    "        restFC=classification.matFiles(dataDir+'rest/'+sub+'_parcel_corrmat.mat')\n",
    "        folds=taskFC.shape[0]\n",
    "        x_train, y_train=classification.concateFC(taskFC, restFC)\n",
    "        CVscores=cross_val_score(clf, x_train, y_train, cv=folds)\n",
    "        mu=CVscores.mean()\n",
    "        acc_scores.append(mu)\n",
    "    dfCV=pd.DataFrame({'sub':subList, 'acc':acc_scores}).set_index('sub')\n",
    "    CV_acc=statsACC(dfCV, 'CV')\n",
    "    return CV_acc\n",
    "    \n",
    "    \n",
    "def statsACC(df, analysis):\n",
    "    if analysis=='CV':\n",
    "        print('cross validation stats')\n",
    "        mu=df.mean()\n",
    "    elif analysis=='SS':\n",
    "        print('same sub stats')\n",
    "        mu=df['acc'].mean()\n",
    "    elif analysis=='DS':\n",
    "        print('diff sub stats')\n",
    "        mu=df['acc'].mean()\n",
    "    elif analysis=='BS':\n",
    "        print('diff sub diff task stats')\n",
    "        mu=df['acc'].mean()\n",
    "    else:\n",
    "        print('skipping stats')\n",
    "    return mu\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model(frames,analysis, train_sub, test_sub, train_task, test_task):\n",
    "    \"\"\"\n",
    "    Preparing machine learning model with appropriate data\n",
    "\n",
    "    Parameters\n",
    "    -------------\n",
    "    classifier : str\n",
    "            The statistical method used for classification\n",
    "    analysis : string\n",
    "            The type of analysis to be conducted\n",
    "    train_sub : str\n",
    "            Subject name for training\n",
    "    test_sub : str\n",
    "            Subject name for testing\n",
    "    train_task : str\n",
    "            Task name for training\n",
    "    test_task : str\n",
    "            Task name for testing\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    total_score : float\n",
    "            Average accuracy of all folds\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    clf=RidgeClassifier()\n",
    "    df=pd.DataFrame()\n",
    "    taskFC=classification.matFiles(framesDir+train_task+'/'+str(frames)+'/'+train_sub+'_parcel_corrmat.mat')\n",
    "    restFC=classification.matFiles(dataDir+'rest/'+train_sub+'_parcel_corrmat.mat')\n",
    "    #if your subs are the same\n",
    "    if train_sub==test_sub:\n",
    "        test_taskFC=classification.matFiles(dataDir+test_task+'/'+test_sub+'_parcel_corrmat.mat')\n",
    "        total_score, acc_score=classification.CV_folds(clf, analysis, taskFC, restFC, test_taskFC, restFC)\n",
    "    else:\n",
    "        test_taskFC=classification.matFiles(dataDir+test_task+'/'+test_sub+'_parcel_corrmat.mat')\n",
    "        test_restFC=classification.matFiles(dataDir+'rest/'+test_sub+'_parcel_corrmat.mat')\n",
    "        total_score, acc_score=classification.CV_folds(clf, analysis, taskFC, restFC, test_taskFC, test_restFC)\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n",
      "cross validation stats\n",
      "same sub stats\n",
      "diff sub stats\n",
      "diff sub diff task stats\n"
     ]
    }
   ],
   "source": [
    "calc_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
